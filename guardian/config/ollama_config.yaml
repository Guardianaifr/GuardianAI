app_name: "GuardianAI [Ollama Shield]"
version: "2.0.0"
guardian_id: "shield-ollama-001"

security_policies:
  block_prompt_injection: true
  validate_output: true
  security_mode: "strict"            # Stricter mode for public/exposed endpoints
  show_block_reason: true
  leak_prevention_strategy: "redact"
  admin_token: "change_me_immediately_to_a_secure_token" # Placeholder for user to change

scanner:
  skills_directory: "./skills"
  blocked_imports: [os, subprocess, sys, socket, requests]
  blocked_functions: [eval, exec, open, system]

runtime_monitoring:
  blocked_processes:
    - nc.exe
    - ncat.exe
    - powershell.exe  # Added for stricter hardening
    - wsl.exe         # Block WSL just in case
  max_cpu_percent: 95.0
  max_memory_percent: 90.0
  check_interval_seconds: 2

proxy:
  enabled: true
  listen_port: 8082               # Different port to avoid conflict with main demo (8081)
  target_url: "http://127.0.0.1:11434" # Standard Ollama Port

backend:
  enabled: true
  url: "http://127.0.0.1:8001/api/v1/telemetry"

rate_limiting:
  enabled: true
  requests_per_minute: 20         # Strict limit for free endpoints (prevent resource abuse)

threat_feed:
  enabled: false
